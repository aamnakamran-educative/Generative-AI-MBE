{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596,
          "referenced_widgets": [
            "37220860d1654b24880e62abc871c0f3",
            "91e69f46642c4ab3b11807b17ac12db1",
            "a0b64dac493144fa92e53ac7e418706a",
            "deb4cabccf914f3085d5c81388907756",
            "d74c87852d454ba7b38cb0ca472f7b02",
            "9d81e1bfd2834b79b2ddcc07cace40f6",
            "7cb1ef30e7e74567a67e2397fdc50764",
            "3a99e3015a6a491c8b9d581b13b6bcac",
            "9036152cfb25402a9974fb9bb44bb041",
            "0c57ef40a91d40a2b7a6cc72189ea5d7",
            "362d1259d443473f8fa965a756b1b4eb"
          ]
        },
        "id": "dT-i28ZiR7rG",
        "outputId": "4e087bf6-c91d-4919-af53-efe201b7853d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /root/tensorflow_datasets/mnist/3.0.1...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Completed...:   0%|          | 0/5 [00:00<?, ? file/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37220860d1654b24880e62abc871c0f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\n",
            "tfds.core.DatasetInfo(\n",
            "    name='mnist',\n",
            "    full_name='mnist/3.0.1',\n",
            "    description=\"\"\"\n",
            "    The MNIST database of handwritten digits.\n",
            "    \"\"\",\n",
            "    homepage='http://yann.lecun.com/exdb/mnist/',\n",
            "    data_dir='/root/tensorflow_datasets/mnist/3.0.1.incompleteS1TYUO',\n",
            "    file_format=tfrecord,\n",
            "    download_size=11.06 MiB,\n",
            "    dataset_size=21.00 MiB,\n",
            "    features=FeaturesDict({\n",
            "        'image': Image(shape=(28, 28, 1), dtype=uint8),\n",
            "        'label': ClassLabel(shape=(), dtype=int64, num_classes=10),\n",
            "    }),\n",
            "    supervised_keys=('image', 'label'),\n",
            "    disable_shuffling=False,\n",
            "    splits={\n",
            "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
            "        'train': <SplitInfo num_examples=60000, num_shards=1>,\n",
            "    },\n",
            "    citation=\"\"\"@article{lecun2010mnist,\n",
            "      title={MNIST handwritten digit database},\n",
            "      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n",
            "      journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},\n",
            "      volume={2},\n",
            "      year={2010}\n",
            "    }\"\"\",\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from functools import partial\n",
        "\n",
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "\n",
        "mnist_builder = tfds.builder(\"mnist\")\n",
        "mnist_builder.download_and_prepare()\n",
        "\n",
        "mnist_train = mnist_builder.as_dataset(split=\"train\")\n",
        "mnist_test = mnist_builder.as_dataset(split=\"test\")\n",
        "\n",
        "info = mnist_builder.info\n",
        "print(info)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Z2DDHoAfR7rL"
      },
      "outputs": [],
      "source": [
        "def flatten_image(x, label=False):\n",
        "    if label:\n",
        "        return (tf.divide(tf.dtypes.cast(tf.reshape(x[\"image\"], (1,28*28)), tf.float32), 256.0) , x[\"label\"])\n",
        "    else:\n",
        "        return (tf.divide(tf.dtypes.cast(tf.reshape(x[\"image\"], (1,28*28)), tf.float32), 256.0))\n",
        "\n",
        "flatten_image = partial(flatten_image, label=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Qo4tWzTWR7rN"
      },
      "outputs": [],
      "source": [
        "# mnist_train.map(flatten_image).take(1)\n",
        "# fig = tfds.show_examples(mnist_train, info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XzDhSG0FR7rO"
      },
      "outputs": [],
      "source": [
        "# for mnist_example in mnist_train.take(1):\n",
        "#   image, label = mnist_example[\"image\"], mnist_example[\"label\"]\n",
        "\n",
        "#   plt.imshow(image.numpy().ravel().reshape(1,-1).astype(np.float32), cmap=plt.get_cmap(\"gray\"))\n",
        "#   print(\"Label: %d\" % label.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "C4-9mwiGR7rP"
      },
      "outputs": [],
      "source": [
        "# mnist_train.map(flatten_image).element_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vOQWCwebR7rQ"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()  # For easy reset of notebook state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_nT5BhAiR7rR"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from functools import partial\n",
        "\n",
        "class DBN(tf.keras.Model):\n",
        "    def __init__(self, rbm_params=None, name='deep_belief_network',\n",
        "                 num_epochs=100, tolerance=1e-3, batch_size=32,\n",
        "                 shuffle_buffer=1024, **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self._rbm_params = rbm_params\n",
        "        self._rbm_layers = list()\n",
        "        self._dense_layers = list()\n",
        "\n",
        "        for num, rbm_param in enumerate(rbm_params):\n",
        "            self._rbm_layers.append(RBM(**rbm_param))\n",
        "            self._rbm_layers[-1].build([rbm_param[\"number_visible_units\"]])\n",
        "\n",
        "            if num < len(rbm_params) - 1:\n",
        "                self._dense_layers.append(\n",
        "                    tf.keras.layers.Dense(\n",
        "                        rbm_param[\"number_hidden_units\"],\n",
        "                        activation=tf.nn.sigmoid))\n",
        "            else:\n",
        "                self._dense_layers.append(\n",
        "                    tf.keras.layers.Dense(\n",
        "                        rbm_param[\"number_hidden_units\"],\n",
        "                        activation=tf.nn.softmax))\n",
        "                self._dense_layers[-1].build([rbm_param[\"number_visible_units\"]])\n",
        "\n",
        "        self._num_epochs = num_epochs\n",
        "        self._tolerance = tolerance\n",
        "        self._batch_size = batch_size\n",
        "        self._shuffle_buffer = shuffle_buffer\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        for dense_layer in self._dense_layers:\n",
        "            x = dense_layer(x)\n",
        "        return x\n",
        "\n",
        "    def train_rbm(self, rbm, inputs, num_epochs, tolerance, batch_size, shuffle_buffer):\n",
        "        last_cost = None\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            cost = 0.0\n",
        "            count = 0.0\n",
        "            for datapoints in inputs.shuffle(shuffle_buffer).batch(batch_size).take(1):\n",
        "                cost += rbm.cd_update(datapoints)\n",
        "                count += 1.0\n",
        "\n",
        "            cost /= count\n",
        "            print(\"epoch: {}, cost: {}\".format(epoch, cost))\n",
        "            if last_cost and abs(last_cost - cost) <= tolerance:\n",
        "                break\n",
        "            last_cost = cost\n",
        "\n",
        "        return rbm\n",
        "\n",
        "    def wake_update(self, x):\n",
        "        with tf.GradientTape(watch_accessed_variables=False) as g:\n",
        "            h_sample = self._rbm_layers[-2].sample_h(x)\n",
        "            for step in range(self._rbm_layers[-2].cd_steps):\n",
        "                v_sample = self._rbm_layers[-2].sample_v(h_sample)\n",
        "                h_sample = self._rbm_layers[-2].sample_h(v_sample)\n",
        "            g.watch(self._rbm_layers[-2].w_gen)\n",
        "            g.watch(self._rbm_layers[-2].vb)\n",
        "            cost = tf.reduce_mean(self._rbm_layers[-2].free_energy(x)) - tf.reduce_mean(\n",
        "                self._rbm_layers[-2].free_energy_reverse(h_sample))\n",
        "        w_grad, vb_grad = g.gradient(cost, [self._rbm_layers[-2].w_gen, self._rbm_layers[-2].vb])\n",
        "        self._rbm_layers[-2].w_gen.assign_sub(self._rbm_layers[-2].learning_rate * w_grad)\n",
        "        self._rbm_layers[-2].vb.assign_sub(self._rbm_layers[-2].learning_rate * vb_grad)\n",
        "        return self._rbm_layers[-2].reconstruction_cost(x).numpy()\n",
        "\n",
        "    def sleep_update(self, x):\n",
        "        with tf.GradientTape(watch_accessed_variables=False) as g:\n",
        "            v_sample = self._rbm_layers[-2].sample_v(x)\n",
        "            for step in range(self._rbm_layers[-2].cd_steps):\n",
        "                h_sample = self._rbm_layers[-2].sample_h(v_sample)\n",
        "                v_sample = self._rbm_layers[-2].sample_v(h_sample)\n",
        "            g.watch(self._rbm_layers[-2].w_rec)\n",
        "            g.watch(self._rbm_layers[-2].hb)\n",
        "            cost = tf.reduce_mean(self._rbm_layers[-2].free_energy(x)) - tf.reduce_mean(\n",
        "                self._rbm_layers[-2].free_energy_reverse(h_sample))\n",
        "        w_rec_grad, hb_grad = g.gradient(cost, [self._rbm_layers[-2].w_rec, self._rbm_layers[-2].hb])\n",
        "        self._rbm_layers[-2].w_rec.assign_sub(self._rbm_layers[-2].learning_rate * w_rec_grad)\n",
        "        self._rbm_layers[-2].hb.assign_sub(self._rbm_layers[-2].learning_rate * hb_grad)\n",
        "        return self._rbm_layers[-2].reconstruction_cost(x).numpy()\n",
        "\n",
        "    def train_dbn(self, inputs):\n",
        "        # pretraining:\n",
        "        inputs_layers = []\n",
        "\n",
        "        for num in range(len(self._rbm_layers)):\n",
        "          if num == 0:\n",
        "            inputs_layers.append(inputs)\n",
        "            self._rbm_layers[num] = self.train_rbm(\n",
        "                self._rbm_layers[num],\n",
        "                inputs_layers[num],\n",
        "                num_epochs=self._num_epochs,\n",
        "                tolerance=self._tolerance,\n",
        "                batch_size=self._batch_size,\n",
        "                shuffle_buffer=self._shuffle_buffer\n",
        "            )\n",
        "          else:\n",
        "            inputs_layers.append(inputs_layers[num - 1].map(self._rbm_layers[num - 1].forward))\n",
        "            self._rbm_layers[num] = self.train_rbm(\n",
        "                self._rbm_layers[num],\n",
        "                inputs_layers[num],\n",
        "                num_epochs=self._num_epochs,\n",
        "                tolerance=self._tolerance,\n",
        "                batch_size=self._batch_size,\n",
        "                shuffle_buffer=self._shuffle_buffer\n",
        "            )\n",
        "\n",
        "        # wake-sleep:\n",
        "        for epoch in range(self._num_epochs):\n",
        "            # Wake pass\n",
        "            inputs_layers = []\n",
        "            for num, rbm in enumerate(self._rbm_layers):\n",
        "                if num == 0:\n",
        "                    inputs_layers.append(inputs)\n",
        "                else:\n",
        "                    inputs_layers.append(inputs_layers[num - 1].map(self._rbm_layers[num - 1].forward))\n",
        "\n",
        "            for num, rbm in enumerate(self._rbm_layers[:-1]):\n",
        "                cost = 0.0\n",
        "                count = 0.0\n",
        "                for datapoints in inputs_layers[num].shuffle(\n",
        "                        self._shuffle_buffer).batch(self._batch_size):\n",
        "                    cost += self._rbm_layers[num].wake_update(datapoints)\n",
        "                    count += 1.0\n",
        "                cost /= count\n",
        "                print(\"epoch: {}, wake_cost: {}\".format(epoch, cost))\n",
        "\n",
        "            # Sleep pass\n",
        "            reverse_inputs = inputs_layers[-1].map(self._rbm_layers[-1].forward)\n",
        "\n",
        "            reverse_inputs_layers = []\n",
        "            for num, rbm in enumerate(self._rbm_layers[::-1]):\n",
        "                if num == 0:\n",
        "                    reverse_inputs_layers.append(reverse_inputs)\n",
        "                else:\n",
        "                    reverse_inputs_layers.append(\n",
        "                        reverse_inputs_layers[num - 1].map(\n",
        "                            self._rbm_layers[len(self._rbm_layers) - num].reverse))\n",
        "\n",
        "            for num, rbm in enumerate(self._rbm_layers[::-1]):\n",
        "                if num > 0:\n",
        "                    cost = 0.0\n",
        "                    count = 0.0\n",
        "                    for datapoints in reverse_inputs_layers[num].shuffle(\n",
        "                            self._shuffle_buffer).batch(self._batch_size):\n",
        "                        cost += self._rbm_layers[len(self._rbm_layers) - 1 - num].sleep_update(datapoints)\n",
        "                        count += 1.0\n",
        "                    cost /= count\n",
        "                    print(\"epoch: {}, sleep_cost: {}\".format(epoch, cost))\n",
        "\n",
        "        # After all epochs, set the weights for dense layers\n",
        "        for dense_layer, rbm_layer in zip(self._dense_layers, self._rbm_layers):\n",
        "            dense_layer.set_weights([rbm_layer.w_rec.numpy(), rbm_layer.hb.numpy()])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DAqzNE-hR7rT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "\n",
        "class RBM(tf.keras.layers.Layer):\n",
        "    def __init__(self, number_hidden_units=10, number_visible_units=None,\n",
        "                 learning_rate=0.1, cd_steps=1):\n",
        "        super().__init__()\n",
        "        self.number_hidden_units = number_hidden_units\n",
        "        self.number_visible_units = number_visible_units\n",
        "        self.learning_rate = learning_rate\n",
        "        self.cd_steps = cd_steps\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "        if not self.number_visible_units:\n",
        "            self.number_visible_units = input_shape[-1]\n",
        "\n",
        "        self.hb = self.add_weight(shape=(self.number_hidden_units, ),\n",
        "                                  initializer='random_normal',\n",
        "                                  trainable=True)\n",
        "        self.vb = self.add_weight(shape=(self.number_visible_units, ),\n",
        "                                  initializer='random_normal',\n",
        "                                  trainable=True)\n",
        "        self.w_rec = self.add_weight(shape=(self.number_visible_units,\n",
        "                                     self.number_hidden_units),\n",
        "                                     initializer='random_normal',\n",
        "                                     trainable=True)\n",
        "        self.w_gen = self.add_weight(shape=(self.number_hidden_units,\n",
        "                                     self.number_visible_units),\n",
        "                                     initializer='random_normal',\n",
        "                                     trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.sigmoid(tf.add(tf.matmul(inputs, self.w_rec), self.hb))\n",
        "\n",
        "    def free_energy(self, x):\n",
        "        return -tf.tensordot(x, self.vb, 1)\\\n",
        "               - tf.reduce_sum(\n",
        "                   tf.math.log(\n",
        "                       1+tf.math.exp(\n",
        "                           tf.add(\n",
        "                               tf.matmul(x, self.w_rec), self.hb))), 1)\n",
        "\n",
        "    def free_energy_reverse(self, x):\n",
        "        return -tf.tensordot(x, self.hb, 1)\\\n",
        "               - tf.reduce_sum(\n",
        "                   tf.math.log(\n",
        "                       1+tf.math.exp(\n",
        "                           tf.add(\n",
        "                               tf.matmul(x, self.w_gen), self.vb))), 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return tf.sigmoid(tf.add(tf.matmul(x, self.w_rec), self.hb))\n",
        "\n",
        "    def sample_h(self, x):\n",
        "        u_sample = tfp.distributions.Uniform().sample((x.shape[1],\n",
        "                                                       self.hb.shape[-1]))\n",
        "        return tf.cast(self.forward(x) > u_sample, tf.float32)\n",
        "\n",
        "    def reverse(self, x):\n",
        "        return tf.sigmoid(tf.add(tf.matmul(x, self.w_gen), self.vb))\n",
        "\n",
        "    def sample_v(self, x):\n",
        "        u_sample = tfp.distributions.Uniform().sample((x.shape[1],\n",
        "                                                       self.vb.shape[-1]))\n",
        "        return tf.cast(self.reverse(x) > u_sample, tf.float32)\n",
        "\n",
        "    def reverse_gibbs(self, x):\n",
        "        return self.sample_h(self.sample_v(x))\n",
        "\n",
        "    def forward_gibbs(self, x):\n",
        "        return self.sample_v(self.sample_h(x))\n",
        "\n",
        "    def wake_update(self, x):\n",
        "        with tf.GradientTape(watch_accessed_variables=False) as g:\n",
        "            h_sample = self.sample_h(x)\n",
        "            for _ in range(self.cd_steps):\n",
        "                v_sample = self.sample_v(h_sample)\n",
        "                h_sample = self.sample_h(v_sample)\n",
        "            g.watch(self.w_gen)\n",
        "            g.watch(self.vb)\n",
        "            cost = tf.reduce_mean(self.free_energy(x)) - tf.reduce_mean(\n",
        "                self.free_energy_reverse(h_sample))\n",
        "        w_grad, vb_grad = g.gradient(cost, [self.w_gen, self.vb])\n",
        "\n",
        "        self.w_gen.assign_sub(self.learning_rate * w_grad)\n",
        "        self.vb.assign_sub(self.learning_rate * vb_grad)\n",
        "\n",
        "        return self.reconstruction_cost(x).numpy()\n",
        "\n",
        "    def sleep_update(self, x):\n",
        "        with tf.GradientTape(watch_accessed_variables=False) as g:\n",
        "            v_sample = self.sample_v(x)\n",
        "            for _ in range(self.cd_steps):\n",
        "                h_sample = self.sample_h(v_sample)\n",
        "                v_sample = self.sample_v(h_sample)\n",
        "            g.watch(self.w_rec)\n",
        "            g.watch(self.hb)\n",
        "            cost = tf.reduce_mean(self.free_energy_reverse(x)) - \\\n",
        "                tf.reduce_mean(self.free_energy(v_sample))\n",
        "        w_grad, hb_grad = g.gradient(cost, [self.w_rec, self.hb])\n",
        "\n",
        "        self.w_rec.assign_sub(self.learning_rate * w_grad)\n",
        "        self.hb.assign_sub(self.learning_rate * hb_grad)\n",
        "\n",
        "        return self.reconstruction_cost_reverse(x).numpy()\n",
        "\n",
        "    def cd_update(self, x):\n",
        "        with tf.GradientTape(watch_accessed_variables=False) as g:\n",
        "\n",
        "            h_sample = self.sample_h(x)\n",
        "            for _ in range(self.cd_steps):\n",
        "                v_sample = tf.constant(self.sample_v(h_sample))\n",
        "                h_sample = self.sample_h(v_sample)\n",
        "\n",
        "            g.watch(self.w_rec)\n",
        "            g.watch(self.hb)\n",
        "            g.watch(self.vb)\n",
        "            cost = tf.reduce_mean(self.free_energy(x)) -\\\n",
        "                tf.reduce_mean(self.free_energy(v_sample))\n",
        "\n",
        "        w_grad, hb_grad, vb_grad = g.gradient(cost,\n",
        "                                              [self.w_rec, self.hb, self.vb])\n",
        "\n",
        "        self.w_rec.assign_sub(self.learning_rate * w_grad)\n",
        "        self.w_gen = tf.Variable(tf.transpose(self.w_rec))  # force tieing\n",
        "        self.hb.assign_sub(self.learning_rate * hb_grad)\n",
        "        self.vb.assign_sub(self.learning_rate * vb_grad)\n",
        "\n",
        "        return self.reconstruction_cost(x).numpy()\n",
        "\n",
        "    def reconstruction_cost(self, x):\n",
        "        return tf.reduce_mean(\n",
        "            tf.reduce_sum(\n",
        "                tf.math.add(\n",
        "                            tf.math.multiply(x,\n",
        "                                             tf.math.log(\n",
        "                                                 self.reverse(\n",
        "                                                     self.forward(x)))),\n",
        "                            tf.math.multiply(tf.math.subtract(1, x),\n",
        "                                             tf.math.log(\n",
        "                                  tf.math.subtract(1, self.reverse(\n",
        "                                                      self.forward(x)))))\n",
        "                            ), 1),)\n",
        "\n",
        "    def reconstruction_cost_reverse(self, x):\n",
        "        return tf.reduce_mean(\n",
        "            tf.reduce_sum(\n",
        "                tf.math.add(\n",
        "                            tf.math.multiply(x,\n",
        "                                             tf.math.log(\n",
        "                                                 self.forward(\n",
        "                                                     self.reverse(x)))),\n",
        "                            tf.math.multiply(\n",
        "                                             tf.math.subtract(1, x),\n",
        "                                             tf.math.log(\n",
        "                                                 tf.math.subtract(1, self.forward(self.reverse(x)))))\n",
        "                            ), 1),)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pyyw8VwoR7rX",
        "scrolled": false,
        "outputId": "f801f0f0-599a-4a73-8194-4be39acf2c82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, cost: -0.702628493309021\n",
            "epoch: 1, cost: -0.6830671429634094\n",
            "epoch: 0, cost: -0.7332688570022583\n",
            "epoch: 1, cost: -0.7301133871078491\n",
            "epoch: 0, cost: -0.8385622501373291\n",
            "epoch: 1, cost: -0.8312234878540039\n",
            "epoch: 0, cost: -0.6931515336036682\n",
            "epoch: 1, cost: -0.6914120316505432\n",
            "epoch: 0, wake_cost: -inf\n",
            "epoch: 0, wake_cost: -inf\n",
            "epoch: 0, wake_cost: -0.703157555993398\n",
            "epoch: 0, sleep_cost: nan\n",
            "epoch: 0, sleep_cost: nan\n",
            "epoch: 0, sleep_cost: nan\n",
            "epoch: 1, wake_cost: nan\n",
            "epoch: 1, wake_cost: nan\n",
            "epoch: 1, wake_cost: nan\n",
            "epoch: 1, sleep_cost: nan\n"
          ]
        }
      ],
      "source": [
        "rbm_params = [\n",
        "        {\"number_hidden_units\": 500, \"number_visible_units\": 784},\n",
        "        {\"number_hidden_units\": 500, \"number_visible_units\": 500},\n",
        "        {\"number_hidden_units\": 2000, \"number_visible_units\": 500},\n",
        "        {\"number_hidden_units\": 10, \"number_visible_units\": 2000}\n",
        "    ]\n",
        "\n",
        "deep_belief_network = DBN(rbm_params, tolerance=1)\n",
        "\n",
        "# pre-training and wake-sleep\n",
        "\n",
        "deep_belief_network.train_dbn(mnist_train.map(lambda x: flatten_image(x, label=False)))\n",
        "\n",
        "# # Save the trained DBN model\n",
        "# with open('dbn_model.pkl', 'wb') as f:\n",
        "#     pickle.dump(deep_belief_network, f)\n",
        "\n",
        "# backpropagation\n",
        "\n",
        "deep_belief_network.compile(loss=tf.keras.losses.CategoricalCrossentropy())\n",
        "deep_belief_network.fit(x=mnist_train.map(lambda x: flatten_image(x, label=True)).batch(32), )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "37220860d1654b24880e62abc871c0f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_91e69f46642c4ab3b11807b17ac12db1",
              "IPY_MODEL_a0b64dac493144fa92e53ac7e418706a",
              "IPY_MODEL_deb4cabccf914f3085d5c81388907756"
            ],
            "layout": "IPY_MODEL_d74c87852d454ba7b38cb0ca472f7b02"
          }
        },
        "91e69f46642c4ab3b11807b17ac12db1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d81e1bfd2834b79b2ddcc07cace40f6",
            "placeholder": "​",
            "style": "IPY_MODEL_7cb1ef30e7e74567a67e2397fdc50764",
            "value": "Dl Completed...: 100%"
          }
        },
        "a0b64dac493144fa92e53ac7e418706a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a99e3015a6a491c8b9d581b13b6bcac",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9036152cfb25402a9974fb9bb44bb041",
            "value": 5
          }
        },
        "deb4cabccf914f3085d5c81388907756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c57ef40a91d40a2b7a6cc72189ea5d7",
            "placeholder": "​",
            "style": "IPY_MODEL_362d1259d443473f8fa965a756b1b4eb",
            "value": " 5/5 [00:02&lt;00:00,  1.83 file/s]"
          }
        },
        "d74c87852d454ba7b38cb0ca472f7b02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d81e1bfd2834b79b2ddcc07cace40f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cb1ef30e7e74567a67e2397fdc50764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a99e3015a6a491c8b9d581b13b6bcac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9036152cfb25402a9974fb9bb44bb041": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0c57ef40a91d40a2b7a6cc72189ea5d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "362d1259d443473f8fa965a756b1b4eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}